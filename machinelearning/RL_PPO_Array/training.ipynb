{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddfd7da-da19-4e78-8879-d12f714210d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, MultiDiscrete\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35558d-ca1c-473d-8c0d-aa191b0fb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be an environment of an array 4*1 (eg. [4,3,2,1] or [1,2,4,3]\n",
    "class ArrayEnv(Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.game_array_size = 100\n",
    "\n",
    "        self.action_space = Discrete(6) #6 possible types of swaps (01,02,03,12,13,23)\n",
    "\n",
    "        high = np.array([1000] * 4)\n",
    "        low = np.array([0] * 4)\n",
    "\n",
    "        self.observation_space = Box(low, high, dtype=np.int16)\n",
    "\n",
    "        #create an array of 100 random numbers between 0 and 1000\n",
    "        self.state = np.random.randint(1000, size=(4))\n",
    "        #game legnth of 100, shouldn't take more than 100 swaps\n",
    "\n",
    "        self.end_array = np.copy(self.state)\n",
    "        self.end_array.sort()\n",
    "\n",
    "    #results when action taken\n",
    "    def step(self, action):\n",
    "        #print(self.state)\n",
    "        #get the two values to swap\n",
    "        if action == 0:\n",
    "            x_indice = 0\n",
    "            y_indice = 1\n",
    "            \n",
    "        elif action == 1:\n",
    "            x_indice = 0\n",
    "            y_indice = 2\n",
    "            \n",
    "        elif action == 2:\n",
    "            x_indice = 0\n",
    "            y_indice = 3\n",
    "            \n",
    "        elif action == 3:\n",
    "            x_indice = 1\n",
    "            y_indice = 2\n",
    "            \n",
    "        elif action == 4:\n",
    "            x_indice = 1\n",
    "            y_indice = 3\n",
    "            \n",
    "        elif action == 5:\n",
    "            x_indice = 2\n",
    "            y_indice = 3\n",
    "        else:\n",
    "            print(\"NO\") #should never get here\n",
    "        \n",
    "\n",
    "        #save the original values in order for ease of reading\n",
    "        x_original = self.state[x_indice]\n",
    "        y_original = self.state[y_indice]\n",
    "\n",
    "        #perform the swap\n",
    "        temp = self.state[x_indice]\n",
    "        self.state[x_indice] = self.state[y_indice]\n",
    "        self.state[y_indice] = temp\n",
    "\n",
    "\n",
    "        #to calculate reward we first need to know how many elements are in the right spot\n",
    "        correct_position = np.count_nonzero(self.state == self.end_array)\n",
    "        # let's only reward if x comes before y in the array to simplify learning\n",
    "        if x_indice < y_indice:\n",
    "            #reward is set to the amount of things in correct position with size relative to\n",
    "            #0.9/100 so that when everything is in place, the reward == 0.9 and then may be added to if the\n",
    "            # movement itself is correct\n",
    "            reward = correct_position*(0.9/4)\n",
    "            #check if value at x is greater than value at y\n",
    "            if x_original > y_original:\n",
    "                #if a large x value is moving down the array\n",
    "                reward +=0.1\n",
    "            else:\n",
    "                #undesirable action i.e. swapping two equal values or moving a large value up in the array\n",
    "                reward = -100\n",
    "\n",
    "        #check if game is over by comparing the current state to the final intended array\n",
    "        if (self.state == self.end_array).all() == True:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        #set placeholder for info\n",
    "        info = {}\n",
    "\n",
    "        #return all data\n",
    "        return self.state, reward, done, info        \n",
    "\n",
    "\n",
    "    #implement printing the array here\n",
    "    def render(self):\n",
    "        #print (np.count_nonzero(self.state == self.end_array))\n",
    "        print(self.state)\n",
    "\n",
    "    #reset/setup the environment\n",
    "    def reset(self):\n",
    "        #reset array to random numbers\n",
    "        self.state = np.random.randint(1000, size=(4))\n",
    "\n",
    "        #create a sorted array for our final state\n",
    "        self.end_array = np.copy(self.state)\n",
    "        self.end_array.sort()\n",
    "        #reset game length\n",
    "\n",
    "        return self.state\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e58fb-82fd-4380-afd5-642fb02cdca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second attempt intended for multiple array lengths\n",
    "class ArrayEnv2(Env):\n",
    "    \n",
    "    def __init__(self, game_size):\n",
    "\n",
    "        self.game_array_size = game_size\n",
    "\n",
    "        self.action_space = MultiDiscrete([self.game_array_size, self.game_array_size]) #10 possible xs and 10 possible ys\n",
    "\n",
    "        high = np.array([1000] * self.game_array_size)\n",
    "        low = np.array([0] * self.game_array_size)\n",
    "\n",
    "        self.observation_space = Box(low, high, dtype=np.int16)\n",
    "\n",
    "        #create an array of 100 random numbers between 0 and 1000\n",
    "        self.state = np.random.randint(1000, size=(self.game_array_size))\n",
    "        #game legnth of 100, shouldn't take more than 100 swaps\n",
    "\n",
    "        self.end_array = np.copy(self.state)\n",
    "        self.end_array.sort()\n",
    "\n",
    "    #results when action taken\n",
    "    def step(self, action):\n",
    "\n",
    "        \n",
    "        x_indice = action[0]\n",
    "        y_indice = action[1]\n",
    "        #print(\"From: {}\\tX: {}\\tY: {}\".format(action, x_indice, y_indice))\n",
    "        #save the original values in order for ease of reading\n",
    "        x_original = self.state[x_indice]\n",
    "        y_original = self.state[y_indice]\n",
    "\n",
    "        #perform the swap\n",
    "        temp = self.state[x_indice]\n",
    "        self.state[x_indice] = self.state[y_indice]\n",
    "        self.state[y_indice] = temp\n",
    "\n",
    "\n",
    "        #to calculate reward we first need to know how many elements are in the right spot\n",
    "        correct_position = np.count_nonzero(self.state == self.end_array)\n",
    "        # let's only reward if x comes before y in the array to simplify learning\n",
    "        if x_indice < y_indice:\n",
    "            #reward is set to the amount of things in correct position with size relative to\n",
    "            #0.9/100 so that when everything is in place, the reward == 0.9 and then may be added to if the\n",
    "            # movement itself is correct\n",
    "            reward = correct_position*(0.9/self.game_array_size)\n",
    "            #check if value at x is greater than value at y\n",
    "            if x_original > y_original:\n",
    "                #if a large x value is moving down the array\n",
    "                reward +=0.1\n",
    "            else:\n",
    "                #undesirable action i.e. swapping two equal values or moving a large value up in the array\n",
    "                reward = -100\n",
    "        else:\n",
    "            reward = -100 #offending line... maybe fix this\n",
    "\n",
    "        #check if game is over by comparing the current state to the final intended array\n",
    "        if (self.state == self.end_array).all() == True:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        #set placeholder for info\n",
    "        info = {}\n",
    "\n",
    "        #return all data\n",
    "        return self.state, reward, done, info        \n",
    "\n",
    "\n",
    "    #implement printing the array here\n",
    "    def render(self):\n",
    "        #print (np.count_nonzero(self.state == self.end_array))\n",
    "        print(self.state)\n",
    "\n",
    "    #reset/setup the environment\n",
    "    def reset(self):\n",
    "        #reset array to random numbers\n",
    "        self.state = np.random.randint(1000, size=(self.game_array_size))\n",
    "\n",
    "        #create a sorted array for our final state\n",
    "        self.end_array = np.copy(self.state)\n",
    "        self.end_array.sort()\n",
    "        #reset game length\n",
    "\n",
    "        return self.state\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277fa21-d36a-40c2-b25e-0dd09eab8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this incorporates a time reward to incentivize speedier solves\n",
    "class ArrayEnv3(Env):\n",
    "    \n",
    "    def __init__(self, game_size):\n",
    "    \n",
    "        self.steps = 0\n",
    "        self.game_array_size = game_size\n",
    "\n",
    "        self.action_space = MultiDiscrete([self.game_array_size, self.game_array_size]) #10 possible xs and 10 possible ys\n",
    "\n",
    "        high = np.array([1000] * self.game_array_size)\n",
    "        low = np.array([0] * self.game_array_size)\n",
    "\n",
    "        self.observation_space = Box(low, high, dtype=np.int16)\n",
    "\n",
    "        #create an array of 100 random numbers between 0 and 1000\n",
    "        self.state = np.random.randint(1000, size=(self.game_array_size))\n",
    "        #game legnth of 100, shouldn't take more than 100 swaps\n",
    "\n",
    "        self.end_array = np.copy(self.state)\n",
    "        self.end_array.sort()\n",
    "\n",
    "    #results when action taken\n",
    "    def step(self, action):\n",
    "        self.steps+=1 #keeps track of how many steps have been completed\n",
    "        \n",
    "        x_indice = action[0]\n",
    "        y_indice = action[1]\n",
    "        #print(\"From: {}\\tX: {}\\tY: {}\".format(action, x_indice, y_indice))\n",
    "        #save the original values in order for ease of reading\n",
    "        x_original = self.state[x_indice]\n",
    "        y_original = self.state[y_indice]\n",
    "\n",
    "        #perform the swap\n",
    "        temp = self.state[x_indice]\n",
    "        self.state[x_indice] = self.state[y_indice]\n",
    "        self.state[y_indice] = temp\n",
    "\n",
    "\n",
    "        #to calculate reward we first need to know how many elements are in the right spot\n",
    "        correct_position = np.count_nonzero(self.state == self.end_array)\n",
    "        # let's only reward if x comes before y in the array to simplify learning\n",
    "        if x_indice < y_indice:\n",
    "            #reward is set to the amount of things in correct position with size relative to\n",
    "            #0.9/100 so that when everything is in place, the reward == 0.9 and then may be added to if the\n",
    "            # movement itself is correct\n",
    "            reward = correct_position*(0.9/self.game_array_size)\n",
    "            #check if value at x is greater than value at y\n",
    "            if x_original > y_original:\n",
    "                #if a large x value is moving down the array\n",
    "                reward +=0.1\n",
    "            else:\n",
    "                #undesirable action i.e. swapping two equal values or moving a large value up in the array\n",
    "                reward = -100\n",
    "\n",
    "        elif x_indice > y_indice:\n",
    "            #reward is set to the amount of things in correct position with size relative to\n",
    "            #0.9/100 so that when everything is in place, the reward == 0.9 and then may be added to if the\n",
    "            # movement itself is correct\n",
    "            reward = correct_position*(0.9/self.game_array_size)\n",
    "            #check if value at x is greater than value at y\n",
    "            if x_original < y_original:\n",
    "                #if a large x value is moving down the array\n",
    "                reward +=0.1\n",
    "            else:\n",
    "                #undesirable action i.e. swapping two equal values or moving a large value up in the array\n",
    "                reward = -100\n",
    "        \n",
    "        else:\n",
    "            reward = -100 #swapping the same array place, useless action\n",
    "\n",
    "        #check if game is over by comparing the current state to the final intended array\n",
    "        \n",
    "        if (self.state == self.end_array).all() == True:\n",
    "            #add in extra reward based off of time it took to solve the array.\n",
    "            if self.steps <= self.game_array_size:\n",
    "                reward+=100\n",
    "            else:\n",
    "                reward += 100/self.steps\n",
    "            \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        #set placeholder for info\n",
    "        info = {}\n",
    "\n",
    "        #return all data\n",
    "        return self.state, reward, done, info        \n",
    "\n",
    "\n",
    "    #implement printing the array here\n",
    "    def render(self):\n",
    "        #print (np.count_nonzero(self.state == self.end_array))\n",
    "        print(self.state)\n",
    "\n",
    "    #reset/setup the environment\n",
    "    def reset(self):\n",
    "        #reset array to random numbers\n",
    "        self.state = np.random.randint(1000, size=(self.game_array_size))\n",
    "\n",
    "        #create a sorted array for our final state\n",
    "        self.end_array = np.copy(self.state)\n",
    "        self.end_array.sort()\n",
    "        #reset game length\n",
    "\n",
    "        return self.state\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08419134-534b-4a5a-9ae7-bf9c7060ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del env\n",
    "#del model\n",
    "env = ArrayEnv3(6)\n",
    "env.reset()\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./PPO_array_6/\", learning_rate = 0.00002, ent_coef = 0.001)\n",
    "model.learn(total_timesteps=10000000, log_interval=4)\n",
    "\n",
    "model.save(\"test6-08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf2c71-fea2-40c8-b7a2-d52876482d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
