{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d39630-026a-481a-bbf2-df7b85a5f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, MultiDiscrete\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "#this incorporates a time reward for speedier solves\n",
    "class ArrayEnv3(Env):\n",
    "    \n",
    "    def __init__(self, game_size):\n",
    "    \n",
    "        self.steps = 0\n",
    "        self.game_array_size = game_size\n",
    "\n",
    "        self.action_space = MultiDiscrete([self.game_array_size, self.game_array_size]) #10 possible xs and 10 possible ys\n",
    "\n",
    "        high = np.array([1000] * self.game_array_size)\n",
    "        low = np.array([0] * self.game_array_size)\n",
    "\n",
    "        self.observation_space = Box(low, high, dtype=np.int16)\n",
    "\n",
    "        #create an array of 100 random numbers between 0 and 1000\n",
    "        self.state = np.random.randint(1000, size=(self.game_array_size))\n",
    "        #game legnth of 100, shouldn't take more than 100 swaps\n",
    "\n",
    "        self.end_array = np.copy(self.state)\n",
    "        self.end_array.sort()\n",
    "\n",
    "    #results when action taken\n",
    "    def step(self, action):\n",
    "        self.steps+=1 #keeps track of how many steps have been completed\n",
    "        \n",
    "        x_indice = action[0]\n",
    "        y_indice = action[1]\n",
    "        #print(\"From: {}\\tX: {}\\tY: {}\".format(action, x_indice, y_indice))\n",
    "        #save the original values in order for ease of reading\n",
    "        x_original = self.state[x_indice]\n",
    "        y_original = self.state[y_indice]\n",
    "\n",
    "        #perform the swap\n",
    "        temp = self.state[x_indice]\n",
    "        self.state[x_indice] = self.state[y_indice]\n",
    "        self.state[y_indice] = temp\n",
    "\n",
    "\n",
    "        #to calculate reward we first need to know how many elements are in the right spot\n",
    "        correct_position = np.count_nonzero(self.state == self.end_array)\n",
    "        # let's only reward if x comes before y in the array to simplify learning\n",
    "        if x_indice < y_indice:\n",
    "            #reward is set to the amount of things in correct position with size relative to\n",
    "            #0.9/100 so that when everything is in place, the reward == 0.9 and then may be added to if the\n",
    "            # movement itself is correct\n",
    "            reward = correct_position*(0.9/self.game_array_size)\n",
    "            #check if value at x is greater than value at y\n",
    "            if x_original > y_original:\n",
    "                #if a large x value is moving down the array\n",
    "                reward +=0.1\n",
    "            else:\n",
    "                #undesirable action i.e. swapping two equal values or moving a large value up in the array\n",
    "                reward = -100\n",
    "\n",
    "        elif x_indice > y_indice:\n",
    "            #reward is set to the amount of things in correct position with size relative to\n",
    "            #0.9/100 so that when everything is in place, the reward == 0.9 and then may be added to if the\n",
    "            # movement itself is correct\n",
    "            reward = correct_position*(0.9/self.game_array_size)\n",
    "            #check if value at x is greater than value at y\n",
    "            if x_original < y_original:\n",
    "                #if a large x value is moving down the array\n",
    "                reward +=0.1\n",
    "            else:\n",
    "                #undesirable action i.e. swapping two equal values or moving a large value up in the array\n",
    "                reward = -100\n",
    "        \n",
    "        else:\n",
    "            reward = -100 #swapping the same array place, useless action\n",
    "\n",
    "        #check if game is over by comparing the current state to the final intended array\n",
    "        \n",
    "        if (self.state == self.end_array).all() == True:\n",
    "            #add in extra reward based off of time it took to solve the array.\n",
    "            if self.steps <= self.game_array_size:\n",
    "                reward+=100\n",
    "            else:\n",
    "                reward += 100/self.steps\n",
    "            \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        #set placeholder for info\n",
    "        info = {}\n",
    "\n",
    "        #return all data\n",
    "        return self.state, reward, done, info        \n",
    "\n",
    "\n",
    "    #implement printing the array here\n",
    "    def render(self):\n",
    "        #print (np.count_nonzero(self.state == self.end_array))\n",
    "        print(self.state)\n",
    "\n",
    "    #reset/setup the environment\n",
    "    def reset(self):\n",
    "        #reset array to random numbers\n",
    "        self.state = np.random.randint(1000, size=(self.game_array_size))\n",
    "\n",
    "        #create a sorted array for our final state\n",
    "        self.end_array = np.copy(self.state)\n",
    "        self.end_array.sort()\n",
    "        #reset game length\n",
    "\n",
    "        return self.state\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f7966-6c10-4ad0-b146-1937f601c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    " #the actual testing bit\n",
    "\n",
    "arr = [1,2,4,5]\n",
    "for i in arr:  \n",
    "#for i in range (1, 6):\n",
    "#del env\n",
    "#del model\n",
    "    model = PPO.load(\"test6-0{}.zip\".format(i))\n",
    "    env = ArrayEnv3(6)\n",
    "\n",
    "    obs = env.reset()\n",
    "    episodes = 1000000\n",
    "    negatives = 0\n",
    "    total_moves = 0\n",
    "    for episode in range(1, episodes+1):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        score = 0 \n",
    "        #print(\"--- original array ---\")\n",
    "        #env.render()\n",
    "        #print(\"--- beginning sort ---\")\n",
    "        moves = 0\n",
    "        #print(\"|\", end=\"\")\n",
    "        while not done:\n",
    "            total_moves+=1\n",
    "            moves+=1\n",
    "            action, _states = model.predict(state)\n",
    "            state, reward, done, info = env.step(action)\n",
    "            score+=reward\n",
    "            #env.render()\n",
    "        if score < 0:\n",
    "            negatives+=1\n",
    "        #print(\"Episode: {} \\tMoves: {}\\tScore: {}\".format(episode, moves, score))\n",
    "\n",
    "    print(\"For test6-0{}\\t avg. moves: {}\\t % Neg: {}\".format(i, (total_moves/episodes), (negatives/episodes)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c8c60-3411-4350-8bdd-f8996609cb0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
